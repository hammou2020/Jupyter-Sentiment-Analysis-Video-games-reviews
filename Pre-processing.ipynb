{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      "reviewText    100 non-null object\n",
      "overall       100 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.7+ KB\n",
      "5    53\n",
      "4    17\n",
      "1    15\n",
      "3    10\n",
      "2     5\n",
      "Name: overall, dtype: int64\n",
      "                                          reviewText  overall  overall_final  \\\n",
      "0  [installing, the, game, was, a, struggle, (, b...        1           -1.0   \n",
      "1  [if, you, like, rally, cars, get, this, game, ...        4            1.0   \n",
      "2  [1st, shipment, received, a, book, instead, of...        1           -1.0   \n",
      "\n",
      "                                          text_final  \n",
      "0  ['instal', 'game', 'struggle', 'game', 'window...  \n",
      "1  ['like', 'rally', 'car', 'get', 'game', 'orien...  \n",
      "2  ['shipment', 'receive', 'book', 'instead', 'sh...  \n",
      "hey yo\n"
     ]
    }
   ],
   "source": [
    "#https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "#import dill\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "        # Reproduce the same result every time if the script is kept consistent otherwise each run will produce different results\n",
    "        np.random.seed(500)\n",
    "    \n",
    "        #[1] Read the data\n",
    "        Corpus = pd.read_json(r\"C:\\Users\\Panos\\Desktop\\Dissert\\Code\\Sample_Video_Games_5.json\", lines=True, encoding='latin-1')\n",
    "        Corpus = Corpus[['reviewText','overall']]\n",
    "        \n",
    "        # Print some info\n",
    "        Corpus.info()\n",
    "        print(Corpus.overall.value_counts())\n",
    "        \n",
    "        #[1.5] Reduce number of classes\n",
    "        for index,entry in enumerate(Corpus['overall']):\n",
    "             if entry == 1.0 or entry == 2.0:\n",
    "                 Corpus.loc[index,'overall_final'] = -1\n",
    "             elif entry == 3.0:\n",
    "                 Corpus.loc[index,'overall_final'] = 0\n",
    "             elif entry == 4.0 or entry == 5.0:\n",
    "                 Corpus.loc[index,'overall_final'] = 1\n",
    "                \n",
    "        #[2] Preprocessing\n",
    "        \n",
    "        # Step - a : Remove blank rows if any.\n",
    "        Corpus['reviewText'].dropna(inplace=True)\n",
    "        # Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "        Corpus['reviewText'] = [entry.lower() for entry in Corpus['reviewText']]\n",
    "        # Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "        Corpus['reviewText'] = [word_tokenize(entry) for entry in Corpus['reviewText']]\n",
    "        # Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "        # WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "        tag_map = defaultdict(lambda : wn.NOUN)\n",
    "        tag_map['J'] = wn.ADJ\n",
    "        tag_map['V'] = wn.VERB\n",
    "        tag_map['R'] = wn.ADV\n",
    "        for index,entry in enumerate(Corpus['reviewText']):\n",
    "            # Declaring Empty List to store the words that follow the rules for this step\n",
    "            Final_words = []\n",
    "            # Initializing WordNetLemmatizer()\n",
    "            word_Lemmatized = WordNetLemmatizer()\n",
    "            # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "            for word, tag in pos_tag(entry):\n",
    "                # Below condition is to check for Stop words and consider only alphabets\n",
    "                if word not in stopwords.words('english') and word.isalpha():\n",
    "                    word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "                    Final_words.append(word_Final)\n",
    "            # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "            Corpus.loc[index,'text_final'] = str(Final_words)\n",
    "            \n",
    "        #Print the first 3 rows\n",
    "        print(Corpus.iloc[:3])\n",
    "        print(\"hey yo\")\n",
    "        \n",
    "        #dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([46, 9, 15])\n"
     ]
    }
   ],
   "source": [
    "        #[3] Prepare Train and Test Data sets\n",
    "            \n",
    "        Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['overall_final'],test_size=0.3)\n",
    "        \n",
    "        print(Counter(Train_Y).values()) # counts the elements' frequency\n",
    "        \n",
    "        #[4] Encoding\n",
    "        \n",
    "        Encoder = LabelEncoder()\n",
    "        Train_Y = Encoder.fit_transform(Train_Y)\n",
    "        Test_Y = Encoder.fit_transform(Test_Y)\n",
    "        \n",
    "        #[5] Word Vectorization\n",
    "        \n",
    "        Tfidf_vect = TfidfVectorizer(max_features=10000)\n",
    "        Test_X_Tfidf = Tfidf_vect.fit_transform(Corpus['text_final'])\n",
    "        Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "        Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "        #[6] SMOTE (Synthetic Minority Over-Sampling Technique)\n",
    "        from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "        \n",
    "        nm = NearMiss(ratio='not minority',random_state=777, version=1, n_neighbors=1)\n",
    "        X_nm, y_nm = nm.fit_sample(Train_X_Tfidf, Train_Y)\n",
    "        \n",
    "        print(Counter(y_nm).values()) # counts the elements' frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instal': 711, 'game': 565, 'struggle': 1335, 'window': 1527, 'live': 799, 'bug': 163, 'championship': 200, 'race': 1072, 'car': 183, 'unlocked': 1455, 'buy': 172, 'addon': 18, 'pay': 986, 'nearly': 908, 'dollar': 381, 'new': 915, 'like': 792, 'idea': 680, 'keep': 743, 'noticed': 931, 'improvement': 691, 'physic': 996, 'graphic': 601, 'compare': 234, 'dirt': 360, 'toss': 1414, 'garbage': 573, 'vow': 1493, 'never': 914, 'another': 49, 'codemasters': 219, 'really': 1101, 'tire': 1407, 'arcade': 68, 'style': 1341, 'continue': 265, 'get': 577, 'fix': 524, 'richard': 1152, 'burn': 169, 'rally': 1079, 'http': 675, 'qid': 1065, 'sr': 1312, 'keywords': 748, 'read': 1093, 'review': 1150, 'enjoy': 424, 'sure': 1352, 'rate': 1087, 'helpful': 650, 'oriented': 962, 'european': 443, 'market': 838, 'since': 1256, 'america': 45, 'huge': 677, 'fan': 486, 'party': 979, 'music': 897, 'even': 444, 'voice': 1490, 'english': 422, 'multiplayer': 896, 'best': 122, 'work': 1541, 'ok': 948, 'shipment': 1235, 'receive': 1107, 'book': 144, 'instead': 717, 'fake': 481, 'one': 952, 'arrive': 72, 'wrong': 1550, 'key': 746, 'inside': 708, 'sealed': 1201, 'box': 151, 'contact': 263, 'send': 1212, 'picture': 998, 'dvd': 397, 'content': 264, 'say': 1190, 'nothing': 928, 'good': 589, 'bye': 174, 'version': 1477, 'turn': 1438, 'mistake': 880, 'console': 260, 'look': 809, 'percent': 989, 'pc': 987, 'deal': 306, 'driver': 389, 'issue': 732, 'numerous': 936, 'thing': 1390, 'go': 587, 'first': 520, 'installation': 713, 'take': 1367, 'minute': 876, 'ridiculous': 1154, 'long': 807, 'load': 800, 'shift': 1231, 'seem': 1206, 'also': 38, 'next': 917, 'many': 832, 'late': 770, 'force': 536, 'internet': 725, 'connection': 258, 'order': 960, 'install': 712, 'regardless': 1118, 'whether': 1518, 'want': 1501, 'play': 1008, 'offline': 946, 'single': 1259, 'player': 1009, 'unleashed': 1451, 'forewarn': 540, 'requirement': 1138, 'prominently': 1047, 'display': 371, 'push': 1061, 'require': 1137, 'sign': 1241, 'account': 8, 'patch': 983, 'update': 1460, 'time': 1405, 'waste': 1507, 'finally': 514, 'hour': 671, 'run': 1173, 'menu': 860, 'screen': 1196, 'text': 1383, 'red': 1113, 'blocky': 135, 'border': 145, 'sun': 1348, 'ugly': 1444, 'pink': 1002, 'reflection': 1116, 'everywhere': 452, 'spend': 1302, 'google': 591, 'find': 515, 'solution': 1281, 'download': 385, 'amd': 44, 'videocard': 1481, 'solve': 1282, 'problem': 1041, 'able': 1, 'perhaps': 992, 'pretty': 1034, 'racing': 1075, 'ever': 447, 'magnificent': 823, 'fun': 561, 'excellent': 457, 'gameplay': 568, 'forcefeedback': 537, 'effect': 406, 'steer': 1320, 'wheel': 1517, 'sense': 1214, 'speed': 1301, 'immersion': 686, 'make': 828, 'top': 1413, 'notch': 927, 'sim': 1246, 'racer': 1073, 'hint': 657, 'feeling': 502, 'suddenly': 1345, 'crash': 285, 'error': 436, 'message': 863, 'anything': 55, 'hang': 626, 'desktop': 335, 'later': 771, 'try': 1433, 'xp': 1552, 'machine': 822, 'less': 785, 'frequently': 554, 'usually': 1466, 'exit': 459, 'random': 1081, 'kill': 751, 'might': 869, 'entire': 430, 'lap': 766, 'great': 606, 'lucky': 821, 'enough': 427, 'stably': 1313, 'mean': 853, 'receipt': 1106, 'fiddle': 505, 'computer': 246, 'totally': 1416, 'reliable': 1128, 'setup': 1225, 'think': 1391, 'copy': 271, 'year': 1555, 'playing': 1010, 'videogames': 1484, 'spent': 1304, 'thousand': 1395, 'faster': 492, 'videocards': 1482, 'cpu': 282, 'grow': 614, 'incompatibility': 695, 'hardware': 634, 'software': 1278, 'publisher': 1057, 'demand': 327, 'well': 1514, 'provide': 1055, 'serial': 1217, 'number': 935, 'utilize': 1467, 'gigabyte': 581, 'harddrive': 632, 'space': 1296, 'online': 953, 'service': 1221, 'store': 1329, 'still': 1325, 'put': 1062, 'stupid': 1339, 'little': 798, 'everytime': 451, 'simple': 1248, 'relax': 1126, 'much': 894, 'do': 376, 'gaming': 571, 'hassle': 637, 'diminish': 357, 'return': 1149, 'costly': 274, 'high': 654, 'resolution': 1141, 'antialiased': 51, 'framerate': 548, 'worth': 1545, 'xbox': 1551, 'come': 228, 'law': 775, 'evident': 454, 'okay': 949, 'start': 1316, 'laptop': 767, 'build': 164, 'collection': 222, 'check': 203, 'perfect': 990, 'compter': 245, 'overall': 968, 'period': 993, 'family': 485, 'personally': 995, 'controller': 268, 'almost': 34, 'necessity': 909, 'type': 1442, 'would': 1547, 'probably': 1040, 'keyboard': 747, 'impossible': 689, 'system': 1365, 'detract': 344, 'greatly': 607, 'must': 898, 'log': 804, 'save': 1187, 'progress': 1046, 'mees': 857, 'longer': 808, 'accept': 6, 'activation': 12, 'code': 218, 'rebuy': 1105, 'customer': 299, 'support': 1350, 'suffers': 1346, 'serious': 1219, 'flaw': 526, 'star': 1315, 'feature': 498, 'love': 816, 'purchase': 1059, 'addition': 17, 'absolutely': 4, 'gorgeous': 592, 'easy': 403, 'configure': 253, 'logitech': 805, 'wireless': 1532, 'rumblepad': 1172, 'evga': 453, 'gtx': 616, 'detail': 339, 'set': 1223, 'full': 559, 'fps': 547, 'blast': 132, 'ca': 175, 'tell': 1376, 'piece': 999, 'everything': 450, 'else': 413, 'microsoft': 867, 'cue': 296, 'apple': 64, 'actually': 15, 'every': 448, 'onto': 954, 'jump': 742, 'series': 1218, 'hoop': 669, 'min': 872, 'accomplish': 7, 'disappointment': 364, 'drive': 387, 'young': 1560, 'boy': 152, 'visiting': 1488, 'hire': 658, 'consultant': 262, 'help': 649, 'oh': 947, 'joystick': 739, 'stop': 1328, 'initially': 706, 'give': 582, 'constantly': 261, 'recently': 1108, 'narrow': 902, 'use': 1464, 'porsche': 1020, 'image': 684, 'span': 1299, 'across': 10, 'three': 1397, 'monitor': 888, 'five': 523, 'annoy': 48, 'application': 65, 'cause': 193, 'occasional': 942, 'figure': 510, 'instructed': 718, 'strange': 1332, 'something': 1284, 'could': 277, 'manage': 830, 'installed': 714, 'scream': 1195, 'bad': 102, 'bombed': 142, 'maybe': 849, 'disc': 365, 'quite': 1070, 'finish': 518, 'tour': 1419, 'mode': 883, 'believe': 119, 'experience': 464, 'bulk': 165, 'offer': 944, 'happy': 628, 'indeed': 699, 'awesome': 97, 'track': 1422, 'highlight': 655, 'snow': 1273, 'various': 1474, 'aspen': 75, 'cool': 269, 'obstacle': 939, 'course': 280, 'pavement': 985, 'felt': 503, 'plague': 1003, 'difficulty': 354, 'spike': 1305, 'win': 1526, 'without': 1536, 'casual': 191, 'lose': 813, 'big': 125, 'medium': 856, 'custom': 298, 'setting': 1224, 'choose': 207, 'level': 787, 'challenge': 197, 'pick': 997, 'assist': 78, 'handle': 624, 'option': 959, 'basically': 109, 'let': 786, 'hold': 663, 'throttle': 1399, 'steering': 1321, 'gradual': 595, 'step': 1322, 'reach': 1091, 'feel': 501, 'sadly': 1178, 'increase': 697, 'dead': 305, 'zone': 1563, 'adjust': 21, 'sensitivity': 1215, 'tweaking': 1440, 'previous': 1035, 'two': 1441, 'handling': 625, 'bit': 128, 'flighty': 529, 'loose': 811, 'ground': 613, 'tighten': 1403, 'somewhat': 1287, 'cigar': 208, 'forward': 544, 'smooth': 1271, 'silk': 1245, 'wih': 1524, 'maxed': 847, 'whatsoever': 1516, 'ignore': 683, 'far': 489, 'early': 400, 'beginning': 118, 'currently': 297, 'feedback': 500, 'colin': 220, 'mc': 851, 'rae': 1077, 'need': 910, 'grid': 610, 'hand': 623, 'simulation': 1254, 'orient': 961, 'gtr': 615, 'gp': 593, 'legend': 783, 'nice': 918, 'pleasant': 1011, 'surprise': 1354, 'limit': 795, 'important': 688, 'point': 1015, 'amaze': 41, 'amazing': 42, 'challenging': 199, 'entertaining': 428, 'racescons': 1074, 'interfacewhat': 724, 'conceptors': 249, 'mind': 873, 'gymkhana': 620, 'pain': 975, 'saw': 1189, 'video': 1480, 'ken': 744, 'block': 134, 'youtube': 1561, 'impressive': 690, 'dream': 386, 'skill': 1263, 'control': 267, 'vehicle': 1475, 'achieve': 9, 'attemps': 89, 'slightly': 1269, 'pointless': 1016, 'extremely': 472, 'interface': 723, 'simply': 1251, 'remotely': 1132, 'messy': 864, 'search': 1203, 'info': 704, 'sponsor': 1309, 'leave': 782, 'lot': 814, 'desire': 334, 'complete': 239, 'rallye': 1080, 'crazy': 286, 'luck': 819, 'spite': 1307, 'criticism': 292, 'definitely': 320, 'regreat': 1119, 'dvdi': 398, 'collect': 221, 'add': 16, 'collectionson': 223, 'wated': 1508, 'gift': 580, 'recipient': 1109, 'fail': 478, 'vista': 1489, 'terrain': 1379, 'money': 887, 'today': 1410, 'miss': 877, 'part': 977, 'forza': 545, 'gran': 596, 'turismo': 1437, 'franchise': 549, 'boat': 139, 'giveaway': 583, 'couple': 279, 'compliant': 242, 'ati': 84, 'card': 184, 'result': 1145, 'people': 988, 'straight': 1331, 'ebay': 405, 'shame': 1229, 'assortment': 80, 'multinational': 895, 'wide': 1521, 'array': 71, 'classic': 213, 'modern': 885, 'ditch': 375, 'comfortable': 230, 'confines': 254, 'sends': 1213, 'headlong': 644, 'gravel': 605, 'world': 1542, 'around': 70, 'wear': 1513, 'veneer': 1476, 'noisy': 923, 'hood': 667, 'call': 178, 'quick': 1068, 'reaction': 1092, 'understanding': 1446, 'road': 1162, 'surface': 1353, 'nerve': 913, 'steel': 1319, 'gamepad': 567, 'certainly': 196, 'stun': 1337, 'engine': 421, 'directx': 359, 'appeal': 61, 'mix': 881, 'prog': 1044, 'rock': 1163, 'job': 736, 'vaguely': 1470, 'model': 884, 'complexity': 241, 'surprisingly': 1355, 'deep': 315, 'condition': 251, 'camera': 179, 'stream': 1333, 'nonstop': 924, 'thrill': 1398, 'launch': 774, 'crest': 291, 'realistic': 1097, 'depiction': 328, 'appear': 62, 'frightening': 557, 'nauseating': 905, 'con': 247, 'brutally': 160, 'fanbase': 487, 'hardcore': 631, 'nut': 937, 'may': 848, 'hard': 630, 'newcomer': 916, 'though': 1393, 'sort': 1293, 'analog': 47, 'confuse': 257, 'familiar': 484, 'rule': 1171, 'racingother': 1076, 'thought': 1394, 'plug': 1014, 'credential': 290, 'export': 467, 'rip': 1159, 'uncomfortable': 1445, 'create': 287, 'identity': 682, 'learn': 780, 'employ': 415, 'fin': 513, 'responsive': 1143, 'wait': 1498, 'till': 1404, 'old': 950, 'hat': 638, 'nope': 925, 'crappy': 284, 'life': 790, 'know': 755, 'lack': 760, 'pass': 980, 'real': 1095, 'reason': 1102, 'bunch': 167, 'extra': 471, 'begin': 117, 'landfirst': 764, 'sound': 1294, 'windowed': 1528, 'end': 417, 'bsod': 161, 'dont': 382, 'rush': 1175, 'test': 1381, 'alive': 32, 'steam': 1318, 'show': 1238, 'finger': 517, 'become': 116, 'suspicious': 1357, 'continuous': 266, 'open': 955, 'bait': 105, 'naive': 900, 'prey': 1037, 'fall': 482, 'anyone': 54, 'honestly': 666, 'personal': 994, 'information': 705, 'particular': 978, 'care': 185, 'publicly': 1056, 'assurance': 83, 'privacy': 1039, 'protection': 1053, 'hollow': 664, 'close': 216, 'oversight': 971, 'nobody': 922, 'different': 351, 'knowingly': 756, 'server': 1220, 'spying': 1310, 'aside': 73, 'carrot': 188, 'stick': 1323, 'reminder': 1131, 'upload': 1461, 'already': 36, 'select': 1209, 'session': 1222, 'way': 1512, 'irritate': 728, 'back': 99, 'unlock': 1454, 'career': 186, 'irritating': 729, 'stuttering': 1340, 'possibly': 1023, 'equipment': 435, 'eye': 473, 'candy': 181, 'plenty': 1013, 'fairly': 480, 'variety': 1473, 'scale': 1191, 'others': 966, 'soley': 1279, 'purpose': 1060, 'farm': 490, 'user': 1465, 'switch': 1360, 'sometimes': 1286, 'entertainment': 429, 'value': 1471, 'briefly': 157, 'anyway': 56, 'opinion': 957, 'truth': 1432, 'boring': 147, 'bore': 146, 'suck': 1344, 'correct': 273, 'ass': 77, 'gear': 575, 'pun': 1058, 'intend': 720, 'folk': 533, 'report': 1136, 'assume': 81, 'either': 410, 'replicate': 1135, 'include': 693, 'uninstalling': 1448, 'rapture': 1084, 'frustrating': 558, 'wish': 1534, 'die': 349, 'bring': 158, 'claim': 210, 'however': 674, 'scam': 1192, 'yay': 1553, 'omg': 951, 'wai': 1497, 'default': 316, 'allow': 33, 'backwords': 101, 'beat': 114, 'gamer': 569, 'hit': 661, 'home': 665, 'see': 1205, 'ego': 408, 'right': 1157, 'everyone': 449, 'afford': 24, 'nvidia': 938, 'overclocked': 969, 'swear': 1358, 'king': 754, 'realism': 1096, 'december': 310, 'program': 1045, 'environment': 431, 'class': 212, 'heap': 646, 'battlefield': 113, 'standard': 1314, 'adicted': 20, 'variable': 1472, 'max': 846, 'thank': 1385, 'god': 588, 'hardly': 633, 'summer': 1347, 'defect': 317, 'appearance': 63, 'fantastic': 488, 'microphone': 866, 'enhance': 423, 'band': 106, 'disappointed': 363, 'tune': 1434, 'light': 791, 'burden': 168, 'kind': 752, 'move': 892, 'anyways': 57, 'fact': 476, 'button': 171, 'bother': 148, 'mainly': 825, 'navigate': 906, 'package': 974, 'fault': 494, 'simplistic': 1249, 'yet': 1557, 'functional': 563, 'design': 332, 'perfectly': 991, 'mic': 865, 'song': 1290, 'harmony': 635, 'singer': 1258, 'mics': 868, 'remain': 1129, 'active': 13, 'rat': 1086, 'mess': 862, 'lead': 777, 'differentiate': 352, 'unless': 1452, 'meaning': 854, 'sing': 1257, 'treat': 1427, 'room': 1165, 'hog': 662, 'house': 672, 'lol': 806, 'gang': 572, 'always': 40, 'join': 737, 'expect': 461, 'score': 1193, 'grandkids': 598, 'parent': 976, 'along': 35, 'guitar': 618, 'recommend': 1111, 'someone': 1283, 'interest': 722, 'wii': 1525, 'rockband': 1164, 'relate': 1123, 'usb': 1463, 'hub': 676, 'refuse': 1117, 'detect': 341, 'wary': 1506, 'compatibility': 235, 'item': 733, 'disapointment': 362, 'decide': 312, 'wonderfully': 1539, 'storyline': 1330, 'fighting': 509, 'minus': 875, 'super': 1349, 'travel': 1426, 'ocean': 943, 'zelda': 1562, 'original': 963, 'son': 1289, 'adventure': 22, 'luckily': 820, 'tip': 1406, 'confront': 256, 'friendly': 556, 'betrayal': 123, 'videogaming': 1485, 'history': 660, 'hated': 640, 'amazon': 43, 'base': 108, 'tale': 1368, 'turd': 1435, 'relation': 1124, 'abomination': 2, 'quality': 1067, 'rather': 1089, 'lackthereof': 761, 'utterly': 1469, 'challengeless': 198, 'lobotomy': 802, 'patient': 984, 'drooling': 391, 'baby': 98, 'feces': 499, 'fill': 511, 'diaper': 348, 'individual': 701, 'severe': 1227, 'case': 190, 'syndrome': 1363, 'easily': 402, 'sit': 1261, 'minimal': 874, 'effort': 407, 'mash': 841, 'spam': 1298, 'gamers': 570, 'eventually': 446, 'atrocious': 87, 'slap': 1266, 'face': 475, 'disney': 370, 'aonuma': 59, 'hideous': 652, 'vomit': 1492, 'inducing': 702, 'originally': 964, 'promise': 1048, 'spaceworld': 1297, 'epic': 433, 'beautiful': 115, 'decidedly': 313, 'lord': 812, 'ring': 1158, 'flare': 525, 'gaudy': 574, 'white': 1519, 'line': 796, 'throughout': 1400, 'wand': 1500, 'wacker': 1496, 'indicate': 700, 'nintendo': 921, 'polish': 1017, 'release': 1127, 'redeemable': 1114, 'inspiring': 710, 'dud': 392, 'likely': 793, 'compose': 243, 'koji': 757, 'kondo': 758, 'rest': 1144, 'detestable': 343, 'saturday': 1186, 'morning': 891, 'cartoon': 189, 'kiddy': 750, 'drivel': 388, 'soccer': 1276, 'mom': 886, 'grandparent': 599, 'approve': 67, 'disrespect': 372, 'stoop': 1327, 'insult': 719, 'near': 907, 'total': 1415, 'kevin': 745, 'costner': 275, 'water': 1509, 'extent': 470, 'fully': 560, 'lawsuit': 776, 'royalty': 1167, 'needless': 911, 'watery': 1510, 'true': 1431, 'green': 608, 'forest': 539, 'field': 506, 'hyrule': 679, 'proper': 1050, 'grave': 604, 'atop': 86, 'child': 205, 'bathe': 111, 'inspire': 709, 'giant': 579, 'bathing': 112, 'simulator': 1255, 'via': 1478, 'fire': 519, 'eiji': 409, 'team': 1373, 'normal': 926, 'develop': 345, 'journalist': 738, 'professional': 1043, 'liar': 788, 'attempt': 90, 'celda': 194, 'videogame': 1483, 'miyamoto': 882, 'vince': 1487, 'mcmahon': 852, 'esque': 439, 'screw': 1197, 'refer': 1115, 'scumbag': 1199, 'sycophant': 1362, 'populate': 1019, 'forum': 543, 'general': 576, 'determine': 342, 'massive': 843, 'success': 1343, 'failure': 479, 'speak': 1300, 'loud': 815, 'clear': 215, 'whole': 1520, 'dog': 380, 'excrement': 458, 'gamecube': 566, 'second': 1204, 'hd': 642, 'envision': 432, 'flop': 531, 'mightily': 870, 'benedict': 120, 'arnold': 69, 'rosenbergs': 1166, 'destine': 337, 'rephrase': 1134, 'quote': 1071, 'ridley': 1155, 'scott': 1194, 'gladiator': 585, 'marcus': 835, 'aurelius': 92, 'lie': 789, 'badass': 103, 'realistically': 1098, 'present': 1030, 'soon': 1291, 'hideously': 653, 'deform': 323, 'debut': 309, 'boo': 143, 'hiss': 659, 'worldwide': 1543, 'hate': 639, 'pour': 1024, 'damage': 301, 'brainwash': 153, 'dishonest': 369, 'community': 233, 'wake': 1499, 'pretend': 1033, 'shill': 1233, 'abandon': 0, 'due': 393, 'upped': 1462, 'disgust': 368, 'nasty': 903, 'unnecessary': 1456, 'debacle': 308, 'hack': 621, 'talent': 1369, 'jimmy': 735, 'fallon': 483, 'japan': 734, 'enable': 416, 'touch': 1417, 'shigeru': 1232, 'ruin': 1170, 'reign': 1122, 'embarrassment': 414, 'majora': 827, 'marvelous': 839, 'marvelously': 840, 'insanely': 707, 'sale': 1182, 'puzzle': 1064, 'npc': 933, 'faux': 495, 'matter': 845, 'suppose': 1351, 'action': 11, 'sword': 1361, 'sorcery': 1292, 'rpg': 1168, 'element': 411, 'throw': 1401, 'completely': 240, 'butcher': 170, 'formula': 542, 'favor': 496, 'elements': 412, 'prefer': 1029, 'bomba': 141, 'discount': 366, 'bin': 126, 'low': 817, 'trash': 1425, 'anycase': 52, 'stone': 1326, 'literally': 797, 'typical': 1443, 'offering': 945, 'rating': 1090, 'lookin': 810, 'hidden': 651, 'puzzels': 1063, 'rateing': 1088, 'ocarina': 941, 'beyond': 124, 'word': 1540, 'cruising': 294, 'powerful': 1025, 'rival': 1160, 'seemingly': 1207, 'endless': 418, 'witch': 1535, 'island': 730, 'wonderful': 1538, 'cruise': 293, 'blue': 138, 'mystery': 899, 'dungeon': 394, 'explore': 466, 'kid': 749, 'terrible': 1380, 'answer': 50, 'yesi': 1556, 'regret': 1120, 'aspect': 74, 'complaint': 238, 'sail': 1179, 'somewhere': 1288, 'sandwich': 1184, 'eat': 404, 'destination': 336, 'relatively': 1125, 'short': 1237, 'worthy': 1546, 'title': 1409, 'yeah': 1554, 'least': 781, 'judgment': 741, 'assumption': 82, 'grandson': 600, 'remember': 1130, 'product': 1042, 'describe': 329, 'unfortunately': 1447, 'signal': 1242, 'cable': 176, 'side': 1240, 'unplug': 1457, 'blow': 137, 'names': 901, 'tv': 1439, 'confidence': 252, 'doubt': 384, 'definition': 321, 'rare': 1085, 'ah': 27, 'inexpensive': 703, 'markedly': 837, 'cabling': 177, 'fine': 516, 'format': 541, 'alittle': 31, 'av': 93, 'untrained': 1458, 'notice': 929, 'diffrence': 355, 'exactly': 455, 'flawlessly': 527, 'definatley': 319, 'leap': 779, 'direction': 358, 'hook': 668, 'besides': 121, 'grate': 603, 'mover': 893, 'pack': 973, 'separate': 1216, 'manual': 831, 'away': 96, 'hawx': 641, 'coop': 270, 'enjoyed': 426, 'plane': 1006, 'bat': 110, 'whatever': 1515, 'anymore': 53, 'several': 1226, 'mission': 879, 'mild': 871, 'spoiler': 1308, 'lt': 818, 'installment': 715, 'clancy': 211, 'eager': 399, 'footage': 535, 'landing': 765, 'map': 833, 'war': 1502, 'worn': 1544, 'clean': 214, 'ton': 1412, 'missile': 878, 'available': 94, 'designer': 333, 'tough': 1418, 'difficult': 353, 'day': 303, 'threat': 1396, 'technology': 1375, 'drone': 390, 'precision': 1028, 'guide': 617, 'bomb': 140, 'expand': 460, 'snap': 1272, 'half': 622, 'wingman': 1531, 'absolute': 3, 'warn': 1503, 'incoming': 694, 'warning': 1504, 'buzzer': 173, 'dodge': 378, 'decent': 311, 'fight': 507, 'lock': 803, 'break': 155, 'escape': 437, 'script': 1198, 'target': 1372, 'engage': 420, 'protect': 1052, 'tank': 1371, 'fighter': 508, 'practically': 1026, 'destroy': 338, 'rid': 1153, 'enemy': 419, 'retreat': 1147, 'overwhelm': 972, 'rebel': 1104, 'russian': 1176, 'nuke': 934, 'wow': 1548, 'death': 307, 'thankfully': 1386, 'skip': 1265, 'thirty': 1392, 'sexist': 1228, 'female': 504, 'pilot': 1000, 'talk': 1370, 'campaign': 180, 'source': 1295, 'instantly': 716, 'sacrifice': 1177, 'alright': 37, 'choice': 206, 'combat': 225, 'aircraft': 29, 'conflict': 255, 'warthog': 1505, 'otherwise': 967, 'french': 553, 'creative': 288, 'president': 1032, 'united': 1450, 'state': 1317, 'wave': 1511, 'intense': 721, 'imagination': 685, 'rank': 1083, 'price': 1038, 'appreciate': 66, 'thanks': 1387, 'chatter': 201, 'spending': 1303, 'dcs': 304, 'blackshark': 130, 'shootem': 1236, 'enjoyable': 425, 'flight': 528, 'stuff': 1336, 'sell': 1210, 'fast': 491, 'blank': 131, 'wing': 1530, 'thats': 1388, 'sometime': 1285, 'ago': 26, 'dose': 383, 'count': 278, 'solid': 1280, 'ture': 1436, 'reallistic': 1100, 'cockpit': 217, 'europe': 442, 'vietnam': 1486, 'sims': 1252, 'sysetm': 1364, 'windows': 1529, 'running': 1174, 'creator': 289, 'research': 1140, 'etc': 441, 'defective': 318, 'bottman': 149, 'incredibly': 698, 'label': 759, 'granddaughter': 597, 'gfx': 578, 'circa': 209, 'intuitive': 727, 'abysmal': 5, 'vstep': 1495, 'backward': 100, 'yoke': 1558, 'quadrent': 1066, 'experice': 463, 'easier': 401, 'trailer': 1423, 'actual': 14, 'higly': 656, 'recomend': 1110, 'sailing': 1180, 'reader': 1094, 'comclacated': 227, 'father': 493, 'seaman': 1202, 'ship': 1234, 'blood': 136, 'eyelid': 474, 'unique': 1449, 'concept': 248, 'maritime': 836, 'centrally': 195, 'focus': 532, 'sink': 1260, 'happen': 627, 'detailed': 340, 'range': 1082, 'cargo': 187, 'passenger': 982, 'rescue': 1139, 'tow': 1420, 'alter': 39, 'succesfully': 1342, 'titanic': 1408, 'york': 1559, 'maiden': 824, 'voyage': 1494, 'simulate': 1253, 'possible': 1022, 'intricacy': 726, 'piloting': 1001, 'operation': 956, 'aspire': 76, 'sea': 1200, 'captian': 182, 'salt': 1183, 'identify': 681, 'goody': 590, 'associate': 79, 'essentially': 440, 'addressed': 19, 'foremost': 538, 'badly': 104, 'voluntary': 1491, 'compression': 244, 'devote': 347, 'harbour': 629, 'tag': 1366, 'plain': 1004, 'factor': 477, 'savour': 1188, 'passage': 981, 'incorporate': 696, 'segment': 1208, 'date': 302, 'comment': 232, 'rig': 1156, 'mass': 842, 'silent': 1243, 'hunter': 678, 'thearatical': 1389, 'medicore': 855, 'wise': 1533, 'simplistically': 1250, 'render': 1133, 'graphical': 602, 'dissappointing': 373, 'novice': 932, 'filler': 512, 'towards': 1421, 'stunt': 1338, 'hover': 673, 'expirience': 465, 'flip': 530, 'buck': 162, 'bargain': 107, 'hope': 670, 'developer': 346, 'viable': 1479, 'simluator': 1247, 'incarnation': 692, 'color': 224, 'grey': 609, 'helm': 648, 'rms': 1161, 'satisfy': 1185, 'decied': 314, 'ot': 965, 'silicone': 1244, 'protective': 1054, 'durable': 396, 'cheap': 202, 'cover': 281, 'doesnt': 379, 'fot': 546, 'tight': 1402, 'extend': 468, 'grip': 611, 'kinda': 753, 'slide': 1268, 'skin': 1264, 'slip': 1270, 'free': 551, 'soft': 1277, 'revise': 1151, 'transaction': 1424, 'previously': 1036, 'seller': 1211, 'reconsider': 1112, 'promptly': 1049, 'obvious': 940, 'last': 769, 'afraid': 25, 'dirty': 361, 'tear': 1374, 'brother': 159, 'lil': 794, 'fit': 521, 'function': 562, 'properly': 1051, 'trim': 1430, 'trigger': 1429, 'marathon': 834, 'black': 129, 'ops': 958, 'tend': 1377, 'sweaty': 1359, 'month': 889, 'sticky': 1324, 'grippy': 612, 'overly': 970, 'especially': 438, 'bumper': 166, 'tension': 1378, 'catch': 192, 'breaker': 156, 'plan': 1005, 'cut': 300, 'apart': 60, 'maker': 829, 'judge': 740, 'merit': 861, 'ahead': 28, 'delivery': 326, 'described': 330, 'texture': 1384, 'slick': 1267, 'plastic': 1007, 'equipent': 434, 'regularly': 1121, 'isopropanal': 731, 'alchohol': 30, 'gumming': 619, 'grade': 594, 'bleed': 133, 'rag': 1078, 'definitly': 322, 'rubber': 1169, 'comfort': 229, 'natural': 904, 'pleased': 1012, 'friend': 555, 'birthday': 127, 'latex': 773, 'glove': 586, 'stretch': 1334, 'complain': 237, 'delicate': 325, 'nicer': 919, 'consider': 259, 'unlike': 1453, 'site': 1262, 'material': 844, 'utmost': 1468, 'importance': 687, 'glad': 584, 'advertise': 23, 'fitting': 522, 'cramp': 283, 'night': 920, 'write': 1549, 'auction': 91, 'cube': 295, 'description': 331, 'laters': 772, 'memory': 859, 'compatible': 236, 'mb': 850, 'retro': 1148, 'quickly': 1069, 'large': 768, 'loads': 801, 'lady': 762, 'dig': 356, 'favorite': 497, 'harvest': 636, 'moon': 890, 'discover': 367, 'expensive': 462, 'trick': 1428, 'doa': 377, 'preserve': 1031, 'precious': 1027, 'future': 564, 'sake': 1181, 'atleast': 85, 'combine': 226, 'length': 784, 'shield': 1230, 'head': 643, 'eventual': 445, 'comfortably': 231, 'distance': 374, 'delay': 324, 'nephew': 912, 'wo': 1537, 'realize': 1099, 'tether': 1382, 'extension': 469, 'freedom': 552, 'avoid': 95, 'wielders': 1522, 'retina': 1146, 'freaken': 550, 'cord': 272, 'heal': 645, 'spine': 1306, 'couch': 276, 'lean': 778, 'brawl': 154, 'melee': 858, 'sibling': 1239, 'squish': 1311, 'together': 1411, 'foot': 534, 'cheep': 204, 'lag': 763, 'survive': 1356, 'poor': 1018, 'anywhere': 58, 'wife': 1523, 'snugly': 1275, 'snug': 1274, 'attach': 88, 'example': 456, 'major': 826, 'concern': 250, 'bough': 150, 'possibility': 1021, 'unwarranted': 1459, 'difference': 350, 'response': 1142, 'durability': 395, 'noticeable': 930, 'reasonable': 1103, 'amermedia': 46, 'heck': 647}\n",
      "  (0, 1541)\t0.2051425277151407\n",
      "  (0, 1325)\t0.2847453985434996\n",
      "  (0, 1205)\t0.37556636638927865\n",
      "  (0, 1157)\t0.3498427808790774\n",
      "  (0, 960)\t0.3498427808790774\n",
      "  (0, 772)\t0.503794401542454\n",
      "  (0, 670)\t0.43284650216296044\n",
      "  (0, 606)\t0.22325247958636127\n",
      "  (1, 1402)\t0.4011306596432279\n",
      "  (1, 809)\t0.24199673991954718\n",
      "  (1, 522)\t0.43714177222422457\n",
      "  (1, 396)\t0.35576202328256823\n",
      "  (1, 240)\t0.4011306596432279\n",
      "  (1, 62)\t0.37558036865288247\n",
      "  (1, 23)\t0.4011306596432279\n",
      "  (2, 1540)\t0.18072659041557157\n",
      "  (2, 1538)\t0.18072659041557157\n",
      "  (2, 1535)\t0.18072659041557157\n",
      "  (2, 1509)\t0.15527539065482468\n",
      "  (2, 1433)\t0.11493619343567762\n",
      "  (2, 1391)\t0.1181311049917367\n",
      "  (2, 1390)\t0.10927603949496752\n",
      "  (2, 1325)\t0.10214695688902607\n",
      "  (2, 1207)\t0.18072659041557157\n",
      "  (2, 1160)\t0.18072659041557157\n",
      "  :\t:\n",
      "  (68, 1408)\t0.3084559304423958\n",
      "  (68, 1185)\t0.33614725986437677\n",
      "  (68, 1161)\t0.33614725986437677\n",
      "  (68, 965)\t0.33614725986437677\n",
      "  (68, 670)\t0.2888086195449675\n",
      "  (68, 648)\t0.33614725986437677\n",
      "  (68, 589)\t0.14896098297463725\n",
      "  (68, 577)\t0.14265232660347626\n",
      "  (68, 565)\t0.11363483470423008\n",
      "  (68, 424)\t0.2197211110795232\n",
      "  (68, 314)\t0.33614725986437677\n",
      "  (68, 172)\t0.15351568517691597\n",
      "  (68, 38)\t0.2197211110795232\n",
      "  (69, 1541)\t0.1504953644814812\n",
      "  (69, 1405)\t0.17142392479899157\n",
      "  (69, 1181)\t0.3695904643874848\n",
      "  (69, 1108)\t0.3175421149046374\n",
      "  (69, 952)\t0.1637810729006832\n",
      "  (69, 950)\t0.25664944956084723\n",
      "  (69, 859)\t0.2755206237646863\n",
      "  (69, 606)\t0.1637810729006832\n",
      "  (69, 566)\t0.23504743274989498\n",
      "  (69, 202)\t0.2870957822327423\n",
      "  (69, 184)\t0.5132988991216945\n",
      "  (69, 172)\t0.33757784250980344\n"
     ]
    }
   ],
   "source": [
    "        #the vocabulary that it has learned from the corpus\n",
    "        print(Tfidf_vect.vocabulary_)\n",
    "        \n",
    "        #the vectorized data\n",
    "        print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  50.0\n",
      "-----------------cm------------------\n",
      "[[ 3  0  2]\n",
      " [ 0  1  0]\n",
      " [ 5  8 11]]\n",
      "-------------------------------------\n",
      "SVM Accuracy Score ->  43.333333333333336\n"
     ]
    }
   ],
   "source": [
    "        #[7] Use the ML Algorithms to Predict the outcome\n",
    "        \n",
    "        # fit the training dataset on the NB classifier\n",
    "        Naive = naive_bayes.MultinomialNB()\n",
    "        Naive.fit(X_nm,y_nm)\n",
    "        # predict the labels on validation dataset\n",
    "        predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "        # Use accuracy_score function to get the accuracy\n",
    "        print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
    "        # Making the confusion matrix\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm = confusion_matrix(Test_Y, predictions_NB)\n",
    "        print(\"-----------------cm------------------\")\n",
    "        print(cm)\n",
    "        print(\"-------------------------------------\")\n",
    "        \n",
    "        #[8] Support Vector Machine\n",
    "        \n",
    "        # Classifier - Algorithm - SVM\n",
    "        # fit the training dataset on the classifier\n",
    "        SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "        SVM.fit(X_nm,y_nm)\n",
    "        # predict the labels on validation dataset\n",
    "        predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "        # Use accuracy_score function to get the accuracy\n",
    "        print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A try to parallelize the for loop\n",
    "# #https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk import pos_tag\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from collections import defaultdict\n",
    "# from nltk.corpus import wordnet as wn\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn import model_selection, naive_bayes, svm\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from collections import Counter\n",
    "\n",
    "# import multiprocessing\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#         # Reproduce the same result every time if the script is kept consistent otherwise each run will produce different results\n",
    "#         np.random.seed(500)\n",
    "    \n",
    "#         #[1] Read the data\n",
    "#         Corpus = pd.read_json(r\"C:\\Users\\Panos\\Desktop\\Dissert\\Code\\Sample_Video_Games_5.json\", lines=True, encoding='latin-1')\n",
    "#         Corpus = Corpus[['reviewText','overall']]\n",
    "        \n",
    "#         # Print some info\n",
    "#         Corpus.info()\n",
    "#         print(Corpus.overall.value_counts())\n",
    "        \n",
    "#         #https://medium.com/@mjschillawski/quick-and-easy-parallelization-in-python-32cb9027e490\n",
    "#         num_cores = multiprocessing.cpu_count()\n",
    "        \n",
    "#         processed_list = Parallel(n_jobs=num_cores)(delayed(my_function(i,parameters) \n",
    "#                                                         for i in enumerate(Corpus['overall'])\n",
    "                \n",
    "#         #[2] Preprocessing\n",
    "        \n",
    "#         # Step - a : Remove blank rows if any.\n",
    "#         Corpus['reviewText'].dropna(inplace=True)\n",
    "#         # Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "#         Corpus['reviewText'] = [entry.lower() for entry in Corpus['reviewText']]\n",
    "#         # Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "#         Corpus['reviewText'] = [word_tokenize(entry) for entry in Corpus['reviewText']]\n",
    "#         # Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "#         # WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "#         tag_map = defaultdict(lambda : wn.NOUN)\n",
    "#         tag_map['J'] = wn.ADJ\n",
    "#         tag_map['V'] = wn.VERB\n",
    "#         tag_map['R'] = wn.ADV\n",
    "#         for index,entry in enumerate(Corpus['reviewText']):\n",
    "#             # Declaring Empty List to store the words that follow the rules for this step\n",
    "#             Final_words = []\n",
    "#             # Initializing WordNetLemmatizer()\n",
    "#             word_Lemmatized = WordNetLemmatizer()\n",
    "#             # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "#             for word, tag in pos_tag(entry):\n",
    "#                 # Below condition is to check for Stop words and consider only alphabets\n",
    "#                 if word not in stopwords.words('english') and word.isalpha():\n",
    "#                     word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "#                     Final_words.append(word_Final)\n",
    "#             # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "#             Corpus.loc[index,'text_final'] = str(Final_words)\n",
    "            \n",
    "#         #Print the first 3 rows\n",
    "#         print(Corpus.iloc[:3])\n",
    "#         print(\"hey yo\")\n",
    "                                                            \n",
    "# def my_function():                                          \n",
    "# #[1.5] Reduce number of classes\n",
    "#         for index,entry in enumerate(Corpus['overall']):\n",
    "#              if entry == 1.0 or entry == 2.0:\n",
    "#                  Corpus.loc[index,'overall_final'] = -1\n",
    "#              elif entry == 3.0:\n",
    "#                  Corpus.loc[index,'overall_final'] = 0\n",
    "#              elif entry == 4.0 or entry == 5.0:\n",
    "#                  Corpus.loc[index,'overall_final'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
